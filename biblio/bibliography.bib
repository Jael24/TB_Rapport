
@online{noauthor_how_nodate,
	title = {How Splunk Enterprise handles your data - Splunk Documentation},
	url = {https://docs.splunk.com/Documentation/Splunk/8.0.3/Data/WhatSplunkdoeswithyourdata},
	urldate = {2020-04-16}
}

@software{noauthor_elasticstack-docker_2020,
	title = {elastic/stack-docker},
	url = {https://github.com/elastic/stack-docker},
	abstract = {Project no longer maintained. Contribute to elastic/stack-docker development by creating an account on {GitHub}.},
	publisher = {elastic},
	urldate = {2020-04-15},
	date = {2020-04-13},
	note = {original-date: 2017-02-01T04:01:15Z}
}

@online{noauthor_test_nodate,
	title = {Test grok patterns},
	url = {http://grokconstructor.appspot.com/do/match#result},
	urldate = {2020-04-09}
}

@online{noauthor_installing_2018,
	title = {Installing the {ELK} Stack on Docker},
	url = {https://logz.io/blog/elk-stack-on-docker/},
	abstract = {The {ELK} Stack can be installed on a variety of different operating systems and in various different setups. Here's how to install the {ELK} Stack on Docker using your Mac.},
	titleaddon = {Logz.io},
	urldate = {2020-04-08},
	date = {2018-02-08},
	langid = {american},
	file = {Snapshot:/home/jael/Zotero/storage/RKFTKFBB/2018 - Installing the ELK Stack on Docker.html:text/html}
}

@online{noauthor_logstash_2018,
	title = {Logstash doesn't receive any logs from filebeat},
	url = {https://discuss.elastic.co/t/logstash-doesnt-receive-any-logs-from-filebeat/140796},
	abstract = {We are getting the following error message in Filebeat       2018-07-19T18:46:18.832Z {ERROR} logstash/async.go:235 Failed to publish events caused by: write tcp 172.17.0.2:42194-{\textgreater}10.14.86.242:9191: write: connection reset by peer     2018-07-19T18:46:19.833Z {ERROR} pipeline/output.go:92 Failed to publish events: write tcp 172.17.0.2:42194-{\textgreater}10.14.86.242:9191: write: connection reset by peer      But the connectivity is {OK}.   root@95eff4da9e80:/etc/filebeat\# telnet 10.14.86.242 9191  Trying 10.14.86...},
	titleaddon = {Discuss the Elastic Stack},
	urldate = {2020-04-02},
	date = {2018-07-19},
	langid = {american},
	note = {Library Catalog: discuss.elastic.co},
	file = {Snapshot:/home/jael/Zotero/storage/7VREP474/140796.html:text/html}
}

@online{noauthor_extract_2017,
	title = {Extract date from message [{SOLVED}]},
	url = {https://discuss.elastic.co/t/extract-date-from-message-solved/87296},
	abstract = {Hello forum,  I'm new to logstash and having issues trying to extract a log substring as timestamp.  The following set May 22 as the @timestamp value:  echo "May 22 12:42:16" {\textbar} ./logstash-5.4.0/bin/logstash -e "input \{ stdin \{\} \} filter \{ date \{ match ={\textgreater} [ {\textbackslash}"message{\textbackslash}", {\textbackslash}"{MMM} dd {HH}:mm:ss{\textbackslash}", {\textbackslash}"{MMM} dd {HH}:mm:ss'-Thread'{\textbackslash}"] \} \}"  \{     "@timestamp" ={\textgreater} 2017-05-22T12:42:16.000Z,       "@version" ={\textgreater} "1",           "host" ={\textgreater} "ubuntu-16",        "message" ={\textgreater} "May 22 12:42:16" \}  However the following fail...},
	titleaddon = {Discuss the Elastic Stack},
	urldate = {2020-04-02},
	date = {2017-05-26},
	langid = {american},
	note = {Library Catalog: discuss.elastic.co},
	file = {Snapshot:/home/jael/Zotero/storage/VY6N6YI8/87296.html:text/html}
}

@online{noauthor_logstash_nodate,
	title = {Logstash {\textbar} {SUPINFO}, École Supérieure d'Informatique},
	url = {https://www.supinfo.com/articles/single/2499-logstash},
	urldate = {2020-04-02},
	file = {Logstash | SUPINFO, École Supérieure d'Informatique:/home/jael/Zotero/storage/GYI2UDT8/2499-logstash.html:text/html}
}

@online{noauthor_splunk_2017,
	title = {Splunk and the {ELK} Stack: A Side-by-Side Comparison},
	url = {https://devops.com/splunk-elk-stack-side-side-comparison/},
	shorttitle = {Splunk and the {ELK} Stack},
	abstract = {This article’s purpose is to compare the “big two” in the log analytics world—Splunk and the {ELK} Stack. But before we go into details, a short},
	titleaddon = {{DevOps}.com},
	urldate = {2020-03-24},
	date = {2017-06-27},
	langid = {american},
	file = {Snapshot:/home/jael/Zotero/storage/6XIPMGEP/2017 - Splunk and the ELK Stack A Side-by-Side Compariso.html:text/html}
}

@online{noauthor_log_2018,
	title = {Log Management Comparison: {ELK} vs Graylog},
	url = {https://coralogix.com/log-analytics-blog/log-management-comparison-elk-vs-graylog/},
	shorttitle = {Log Management Comparison},
	abstract = {Production logs can help ensure application security, reveal business insights and find and understand errors, crashes, and exceptions. But as useful as logs are, they're difficult to manage and hard to keep track of.},
	titleaddon = {Coralogix - Smarter Log Analytics},
	urldate = {2020-03-23},
	date = {2018-06-03},
	langid = {american},
	file = {Snapshot:/home/jael/Zotero/storage/5VP8HZXD/2018 - Log Management Comparison ELK vs Graylog.html:text/html}
}

@online{noauthor_abonnements_nodate,
	title = {Abonnements {\textbar} Produits et support technique de la Suite Elastic {\textbar} Elastic},
	url = {https://www.elastic.co/fr/subscriptions#contact-us},
	abstract = {Découvrez les différents niveaux d'abonnement, les tarifs et les fonctionnalités des déploiements de la Suite Elastic (Elasticsearch Kibana, Beats et Logstash) sur site, d'Elastic Cloud et d'Elastic Cloud Enterprise.},
	urldate = {2020-03-23},
	langid = {french},
	file = {Snapshot:/home/jael/Zotero/storage/4NA9M23C/Abonnements  Produits et support technique de la .html:text/html}
}

@online{noauthor_complete_2016,
	title = {The Complete Guide to the {ELK} Stack},
	url = {https://logz.io/learn/complete-guide-elk-stack/},
	abstract = {The Logz.io authoritative guide to the {ELK} Stack that shows the best practices for installation, monitoring, logging and log analysis.},
	titleaddon = {Logz.io},
	urldate = {2020-03-22},
	date = {2016-05-23},
	langid = {american},
	file = {Snapshot:/home/jael/Zotero/storage/F28XWATQ/2016 - The Complete Guide to the ELK Stack.html:text/html}
}

@online{noauthor_best_nodate,
	title = {Best Log Manager Software \& Tools for Log Monitoring \& Events for 2020},
	url = {https://www.ittsystems.com/log-manager-software-and-tools/},
	abstract = {Finding the Best Log Manager Software \& Tools for your Infrastructure is a Daunting Task - So here's a List of the Top Tools \& Software [ Free Download! ]},
	titleaddon = {{ITT} Systems},
	urldate = {2020-03-21},
	langid = {american},
	file = {Snapshot:/home/jael/Zotero/storage/327RME89/Best Log Manager Software & Tools for Log Monitori.html:text/html}
}

@online{noauthor_beats_nodate,
	title = {Beats overview {\textbar} Beats Platform Reference [7.6] {\textbar} Elastic},
	url = {https://www.elastic.co/guide/en/beats/libbeat/7.6/beats-reference.html},
	type = {Learn/Docs/Libbeat/Reference/7.6},
	urldate = {2020-05-06},
	langid = {english},
	file = {Snapshot:/home/jael/Zotero/storage/VNT7SGDU/Beats overview  Beats Platform Reference [7.6]  .html:text/html}
}

@online{noauthor_installing_nodate,
	title = {Installing the Elastic Stack {\textbar} Installation and Upgrade Guide [7.6] {\textbar} Elastic},
	url = {https://www.elastic.co/guide/en/elastic-stack/current/installing-elastic-stack.html},
	type = {Learn/Docs/Elastic Stack/Installation and Upgrade/7.6},
	urldate = {2020-05-06},
	langid = {english},
	file = {Snapshot:/home/jael/Zotero/storage/ZVTGNIZU/Installing the Elastic Stack  Installation and Up.html:text/html}
}

@inreference{noauthor_iso_2020,
	title = {{ISO} 8601},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://fr.wikipedia.org/w/index.php?title=ISO_8601&oldid=169232031},
	abstract = {La norme internationale {ISO} 8601 spécifie la représentation numérique de la date et de l'heure — respectivement basées sur le calendrier grégorien et le système horaire de 24 heures. Cette notation, créée en 1988, est particulièrement destinée à éviter tout risque de confusion dans les communications internationales due au grand nombre de notations nationales différentes. Elle a en outre de nombreux avantages pour une utilisation informatique par rapport aux autres notations. 
Il y a six niveaux de granularité dans ce format, selon les applications. Pour cette raison, il est possible d'omettre certains éléments.
Exemples :

1977-04-22T01:00:00-05:00 correspond au 22 avril 1977, à 1 h du matin  heure normale de l'est de l'Amérique du Nord (soit 5 heures de décalage).
1977-04-22T06:00:00Z correspond au même instant.Il faut cependant noter que l'organisation internationale de normalisation ({ISO} 8601) dissipe toute confusion en établissant, pour la représentation de la date, un format internationalement reconnu : {YYYY}-{MM}-{DD}},
	booktitle = {Wikipédia},
	urldate = {2020-05-08},
	date = {2020-04-06},
	langid = {french},
	note = {Page Version {ID}: 169232031},
	file = {Snapshot:/home/jael/Zotero/storage/NJJ99AZ9/2020 - ISO 8601.html:text/html}
}

@online{noauthor_what_nodate,
	title = {What Is Log Management? A Complete Logging Guide {\textbar} The Graylog Blog},
	url = {https://www.graylog.org/post/what-is-log-management-a-complete-logging-guide},
	urldate = {2020-05-08},
	file = {What Is Log Management? A Complete Logging Guide | The Graylog Blog:/home/jael/Zotero/storage/AJPBN2ZF/what-is-log-management-a-complete-logging-guide.html:text/html}
}

@inreference{noauthor_gestion_2019,
	title = {Gestion des logs},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://fr.wikipedia.org/w/index.php?title=Gestion_des_logs&oldid=160258700},
	abstract = {La gestion de logs ({LM} pour Log Management) comprend une approche de la gestion de grands volumes des messages de log  générés par l'ordinateur (aussi connu comme journaux d'évènements, journalisation, etc.). La gestion des logs concerne en général:

La collecte des logs
L'agrégation centralisée des logs
Le stockage à long terme et la durée de rétention des logs
La rotation des fichiers de logs
L'analyse des logs (en temps réel et en vrac après une période de stockage)
Les rapports et l'étude des logs.},
	booktitle = {Wikipédia},
	urldate = {2020-05-08},
	date = {2019-06-19},
	langid = {french},
	note = {Page Version {ID}: 160258700},
	file = {Snapshot:/home/jael/Zotero/storage/3PA8E6S9/index.html:text/html}
}

@online{noauthor_top_nodate,
	title = {Top 8 {BEST} Log Management Software {\textbar} Log Analysis Tool Review 2020},
	url = {https://www.softwaretestinghelp.com/log-management-software/},
	urldate = {2020-05-08},
	file = {Top 8 BEST Log Management Software | Log Analysis Tool Review 2020:/home/jael/Zotero/storage/6ZH96WRL/log-management-software.html:text/html}
}

@online{noauthor_6_2019,
	title = {6 Best Log Management Tools For Linux in 2020},
	url = {https://www.addictivetips.com/net-admin/linux-log-management-tools/},
	abstract = {Let's have an in-depth look at the best Log Management For Linux. We're looking at the technologies and the tools available for the open-source {OS}.},
	titleaddon = {{AddictiveTips}},
	urldate = {2020-05-08},
	date = {2019-08-23},
	langid = {american},
	note = {Library Catalog: www.addictivetips.com
Section: Network Admin},
	file = {Snapshot:/home/jael/Zotero/storage/IWTQ38S3/linux-log-management-tools.html:text/html}
}

@online{says_ten_2019,
	title = {Ten alternatives to Cronolog},
	url = {https://www.comparitech.com/net-admin/log-management-tools/},
	abstract = {Cronolog was a great little tool for splitting up Apache log files. The utility is no longer available. The software industry has created some really great log management systems over the past few years and we list the best alternatives to Cronolog.},
	titleaddon = {Comparitech},
	author = {says, Ayushi Sharma},
	urldate = {2020-05-08},
	date = {2019-03-01},
	langid = {american},
	note = {Library Catalog: www.comparitech.com
Section: Net Admin},
	file = {Snapshot:/home/jael/Zotero/storage/459VX53M/log-management-tools.html:text/html}
}

@online{noauthor_google_nodate,
	title = {Google Trends},
	url = {https://trends.google.fr/trends/explore?date=2010-04-23%202020-04-23&q=graylog,Loggly,Elasticsearch,Splunk},
	abstract = {Découvrir les recherches sur "graylog" par période, lieu et popularité sur Google Trends},
	titleaddon = {Google Trends},
	urldate = {2020-05-08},
	langid = {french},
	note = {Library Catalog: trends.google.fr},
	file = {Snapshot:/home/jael/Zotero/storage/XL3D42UA/explore.html:text/html}
}

@software{jael24_jael24tb_elasticstack_2020,
	title = {Jael24/{TB}\_ElasticStack},
	rights = {{MIT}},
	url = {https://github.com/Jael24/TB_ElasticStack},
	abstract = {Repository for a complete working Elastic Stack pipeline (Logstash},
	author = {{Jael24}},
	urldate = {2020-05-14},
	date = {2020-05-13},
	note = {original-date: 2020-04-15T08:28:17Z}
}

@software{jael24_jael24tb_fielddevices_2020,
	title = {Jael24/{TB}\_fieldDevices},
	rights = {{MIT}},
	url = {https://github.com/Jael24/TB_fieldDevices},
	abstract = {Application to be launched on the field devices for the use-case implementation (run {GridEye} Simulator, Filebeat, Metricbeat and {PostgreSQL}). Running with Docker.},
	author = {{Jael24}},
	urldate = {2020-06-05},
	date = {2020-05-29},
	note = {original-date: 2020-05-20T12:44:21Z}
}

@online{noauthor_tartemovdocker-postgres-elk_nodate,
	title = {tartemov/docker-postgres-elk},
	url = {https://github.com/tartemov/docker-postgres-elk},
	abstract = {{PostgreSQL} and Beats containers with docker-compose configuration - tartemov/docker-postgres-elk},
	titleaddon = {{GitHub}},
	urldate = {2020-05-22},
	langid = {english}
}

@online{coste_powerful_2018,
	title = {Powerful logging with Docker, Filebeat and Elasticsearch},
	url = {https://medium.com/@bcoste/powerful-logging-with-docker-filebeat-and-elasticsearch-8ad021aecd87},
	abstract = {To perform an efficient log analysis, the {ELK} stack is still a good choice, even with Docker.},
	titleaddon = {Medium},
	author = {{COSTE}, Bruno},
	urldate = {2020-05-18},
	date = {2018-06-13},
	langid = {english},
	file = {Snapshot:/home/jael/Zotero/storage/3IAFG345/COSTE - 2018 - Powerful logging with Docker, Filebeat and Elastic.html:text/html}
}

@online{noauthor_depsys_nodate,
	title = {{DEPsys} solution : {GridEye}},
	url = {https://www.depsys.ch/solutions/},
	shorttitle = {{DEPsys} solution},
	abstract = {{GridEye} : Digital Grid Optimizer for Power Distribution Networks},
	titleaddon = {{DEPsys}},
	urldate = {2020-06-16},
	langid = {english},
	file = {Snapshot:/home/jael/Zotero/storage/WBV7ZFXX/DEPsys solution  GridEye.html:text/html}
}

@software{jael24_jael24tb_grideye_simulator_2020,
	title = {Jael24/{TB}\_GridEye\_Simulator},
	rights = {{MIT}},
	url = {https://github.com/Jael24/TB_GridEye_Simulator},
	abstract = {Minimal simulator of {GridEye} infrastructure. Generate logs.},
	author = {{Jael24}},
	urldate = {2020-06-18},
	date = {2020-05-13},
	note = {original-date: 2020-05-08T10:12:58Z}
}

@online{noauthor_siem_nodate,
	title = {{SIEM}, {AIOps}, Gestion des applications, Gestion des logs, Machine learning et Conformité},
	url = {https://www.splunk.com/fr_fr},
	abstract = {Splunk Inc. transforme les données grâce à la seule plateforme Data-to- Everything capable de relever les défis les plus ambitieux en matière d’{IT}, d’{IoT}, de sécurité et de données.},
	titleaddon = {Splunk},
	urldate = {2020-07-14},
	langid = {french},
	file = {Snapshot:/home/jael/Zotero/storage/47DIZKM4/SIEM, AIOps, Gestion des applications, Gestion des.html:text/html}
}

@online{noauthor_detec_nodate,
	title = {{DETEC} - Stratégie énergétique 2050},
	url = {https://www.uvek.admin.ch/uvek/fr/home/energie/strategie-energetique-2050.html},
	urldate = {2020-07-14}
}

@online{noauthor_logiciels_nodate,
	title = {Logiciels de gestion informatique et outils de surveillance à distance {\textbar} {SolarWinds}},
	url = {https://www.solarwinds.com/fr},
	abstract = {Les solutions de gestion et de surveillance informatiques de {SolarWinds} sont conçues pour les administrateurs système et ingénieurs réseau en quête d’outils puissants et abordables. Obtenez un essai gratuit dès aujourd’hui.},
	urldate = {2020-07-14},
	langid = {french},
	file = {Snapshot:/home/jael/Zotero/storage/2AEZA5PC/Logiciels de gestion informatique et outils de sur.html:text/html}
}

@online{noauthor_sematext_nodate,
	title = {Sematext: Cloud Monitoring \& Management Tools},
	url = {https://sematext.com/},
	shorttitle = {Sematext},
	abstract = {Powerful monitoring and management solutions for smart devops teams that want to move faster. Try Sematext now with a 30 days free trial!},
	titleaddon = {Sematext},
	urldate = {2020-07-14},
	langid = {american},
	file = {Snapshot:/home/jael/Zotero/storage/Q24V6ZFK/Sematext Cloud Monitoring & Management Tools.html:text/html}
}

@online{noauthor_postgresql_nodate,
	title = {{PostgreSQL}: The world's most advanced open source database},
	url = {https://www.postgresql.org/},
	urldate = {2020-07-14}
}

@online{noauthor_logstash_nodate-1,
	title = {Logstash : collecte, transformation et analyse de logs},
	url = {https://www.elastic.co/fr/logstash},
	shorttitle = {Logstash},
	abstract = {Logstash (qui fait partie de la Suite Elastic) est un pipeline open source flexible, conçu pour la collecte, l'analyse et l'enrichissement des données, qu'il intègre depuis toutes les sources, et quel que soit leur format. Téléchargez-le gratuitement.},
	titleaddon = {Elastic},
	urldate = {2020-07-14},
	langid = {french},
	file = {Snapshot:/home/jael/Zotero/storage/FZMF8HCD/Logstash  collecte, transformation et analyse de .html:text/html}
}

@online{noauthor_log_nodate,
	title = {Log Analysis {\textbar} Log Management by Loggly},
	url = {https://www.loggly.com/},
	urldate = {2020-07-14}
}

@online{noauthor_kibana_nodate,
	title = {Kibana : Exploration, visualisation et découverte des données {\textbar} Elastic},
	url = {https://www.elastic.co/fr/kibana},
	urldate = {2020-07-14}
}

@online{noauthor_java_nodate,
	title = {Java {\textbar} Oracle},
	url = {https://www.java.com/fr/},
	urldate = {2020-07-14}
}

@online{noauthor_industry_nodate,
	title = {Industry Leading Log Management {\textbar} Graylog},
	url = {https://www.graylog.org/},
	urldate = {2020-07-14}
}

@online{noauthor_google_nodate-1,
	title = {Google},
	url = {https://www.google.com/},
	urldate = {2020-07-14}
}

@online{noauthor_recherche_nodate,
	title = {Recherche \& Analyses en Open Source • Elasticsearch {\textbar} Elastic},
	url = {https://www.elastic.co/fr/},
	abstract = {Nous sommes les créateurs d'Elasticsearch, Kibana, Beats et Logstash, aussi connu sous le nom de Suite Elastic. Recherchez, analysez et visualisez vos données da façon sécurisée et fiable.},
	urldate = {2020-07-14},
	langid = {french},
	file = {Snapshot:/home/jael/Zotero/storage/9BX488GX/Recherche & Analyses en Open Source • Elasticsearc.html:text/html}
}

@online{noauthor_elasticsearch_nodate,
	title = {Elasticsearch : Le moteur de recherche et d'analyse distribué officiel},
	url = {https://www.elastic.co/fr/elasticsearch},
	shorttitle = {Elasticsearch},
	abstract = {Elasticsearch est le moteur de recherche et d'analyse {RESTful} distribué leader du marché. Il est conçu pour une évolutivité horizontale, une fiabilité maximale et une gestion simplifiée. Le tout, en open source. Lancez-vous gratuitement.},
	titleaddon = {Elastic},
	urldate = {2020-07-14},
	langid = {french},
	file = {Snapshot:/home/jael/Zotero/storage/C9BVQ9C6/Elasticsearch  Le moteur de recherche et d'analys.html:text/html}
}

@online{noauthor_overview_2020,
	title = {Overview of Docker Compose},
	url = {https://docs.docker.com/compose/},
	abstract = {Introduction and Overview of Compose},
	titleaddon = {Docker Documentation},
	urldate = {2020-07-14},
	date = {2020-07-13},
	langid = {english},
	file = {Snapshot:/home/jael/Zotero/storage/FGQXSSIV/2020 - Overview of Docker Compose.html:text/html}
}

@online{noauthor_empowering_nodate,
	title = {Empowering App Development for Developers {\textbar} Docker},
	url = {https://www.docker.com/},
	abstract = {Learn how Docker helps developers bring their ideas to life by conquering the complexity of app development.},
	urldate = {2020-07-14},
	langid = {english},
	file = {Snapshot:/home/jael/Zotero/storage/33J46K8K/Empowering App Development for Developers  Docker.html:text/html}
}

@online{noauthor_dnsstuff_nodate,
	title = {{DNSstuff} - Reviews {\textbar} Opinions {\textbar} Tools},
	url = {https://www.dnsstuff.com/},
	abstract = {Reviews {\textbar} Opinions {\textbar} Tools},
	titleaddon = {{DNSstuff}},
	urldate = {2020-07-14},
	langid = {american},
	file = {Snapshot:/home/jael/Zotero/storage/N9F9MS4C/DNSstuff - Reviews  Opinions  Tools.html:text/html}
}

@online{noauthor_agents_nodate,
	title = {Agents Beats : Agents de transfert de données pour Elasticsearch},
	url = {https://www.elastic.co/fr/beats},
	shorttitle = {Agents Beats},
	abstract = {La plateforme open source qui permet de créer des agents de transfert pour les données de logs, de réseau, ou encore d'infrastructure – et qui s'intègre à Elasticsearch, Kibana et Logstash.},
	titleaddon = {Elastic},
	urldate = {2020-07-14},
	langid = {french},
	file = {Snapshot:/home/jael/Zotero/storage/A6W4IGWB/Agents Beats  Agents de transfert de données pour.html:text/html}
}

@online{brownlee_how_2017,
	title = {How to Create an {ARIMA} Model for Time Series Forecasting in Python},
	url = {https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/},
	abstract = {A popular and widely used statistical method for time series forecasting is the {ARIMA} model. {ARIMA} is an acronym that stands for {AutoRegressive} Integrated Moving Average. It is a class of model that captures a suite of different standard temporal structures in time series data. In this tutorial, you will discover how to develop an […]},
	titleaddon = {Machine Learning Mastery},
	author = {Brownlee, Jason},
	urldate = {2020-07-06},
	date = {2017-01-08},
	langid = {american},
	file = {Snapshot:/home/jael/Zotero/storage/FRRGG2CP/Brownlee - 2017 - How to Create an ARIMA Model for Time Series Forec.html:text/html}
}

@online{noauthor_chris1610pbpython_nodate,
	title = {chris1610/pbpython},
	url = {https://github.com/chris1610/pbpython},
	abstract = {Code, Notebooks and Examples from Practical Business Python - chris1610/pbpython},
	titleaddon = {{GitHub}},
	urldate = {2020-07-01},
	langid = {english},
	file = {Snapshot:/home/jael/Zotero/storage/5RAD2A2W/chris1610pbpython.html:text/html}
}

@software{zhao_yzhao062anomaly-detection-resources_2020,
	title = {yzhao062/anomaly-detection-resources},
	rights = {{AGPL}-3.0 License         ,                 {AGPL}-3.0 License},
	url = {https://github.com/yzhao062/anomaly-detection-resources},
	abstract = {Anomaly detection related books, papers, videos, and toolboxes},
	author = {Zhao, Yue},
	urldate = {2020-07-20},
	date = {2020-07-20},
	note = {original-date: 2018-05-16T20:02:54Z},
	keywords = {anomaly-detection, awesome, awesome-list, data-mining, outlier, outlier-detection, outlier-ensembles, time-series-analysis}
}

@online{noauthor_introduction_2019,
	title = {Introduction to Predictive Analytics Anomaly Detection},
	url = {https://stratusinnovations.com/blog/introduction-to-predictive-analytics-anomaly-detection/},
	abstract = {Predictive maintenance and pay-per-use machinery can help your company avoid unnecessary downtime and save hundreds of thousands of dollars each year.},
	titleaddon = {Stratus Innovations Group},
	urldate = {2020-07-27},
	date = {2019-04-25},
	langid = {american},
	file = {Snapshot:/home/jael/Zotero/storage/HTNHC2AN/2019 - Introduction to Predictive Analytics Anomaly Detec.html:text/html}
}

@online{noauthor_what_2020,
	title = {What is anomaly detection, and why you need it.},
	url = {https://thedatascientist.com/anomaly-detection-why-you-need-it/},
	abstract = {An Introduction to Anomaly Detection and Its Importance in Machine {LearningData} is becoming increasingly important in almost every conceivable field and area. From business and healthcare to law enforcement and sports, data is central to their operations. It’s not enough to simply collect information however. Instead, you need to make good use of it, and […]},
	titleaddon = {The Data Scientist},
	urldate = {2020-07-27},
	date = {2020-02-14},
	langid = {american},
	file = {Snapshot:/home/jael/Zotero/storage/Q949E4VE/2020 - What is anomaly detection, and why you need it..html:text/html}
}

@online{noauthor_-demand_2018,
	title = {On-demand forecasting with machine learning in Elasticsearch},
	url = {https://www.elastic.co/fr/blog/elasticsearch-machine-learning-on-demand-forecasting},
	abstract = {La prévision à la demande: Machine Learning peut modéliser vos données et prédire plusieurs intervalles de temps dans le futur.},
	titleaddon = {Elastic Blog},
	urldate = {2020-07-28},
	date = {2018-01-10},
	langid = {french},
	file = {Snapshot:/home/jael/Zotero/storage/GH5KC622/2018 - On-demand forecasting with machine learning in Ela.html:text/html}
}

@online{noauthor_machine_nodate,
	title = {Machine Learning pour Elasticsearch},
	url = {https://www.elastic.co/fr/what-is/elasticsearch-machine-learning},
	abstract = {Les fonctionnalités de Machine Learning d'Elastic modélisent automatiquement le comportement de vos données Elasticsearch (tendances, périodicité, etc.). Le tout, en temps réel. Leur mission : identifier les problèmes plus rapidement, rationaliser l'analyse des causes et réduire le nombre de faux positifs.},
	titleaddon = {Elastic},
	urldate = {2020-07-28},
	langid = {french},
	note = {Library Catalog: www.elastic.co},
	file = {Snapshot:/home/jael/Zotero/storage/3M79P2SM/elasticsearch-machine-learning.html:text/html}
}

@online{noauthor_performing_nodate,
	title = {Performing population analysis {\textbar} Machine Learning in the Elastic Stack [7.8] {\textbar} Elastic},
	url = {https://www.elastic.co/guide/en/machine-learning/current/ml-configuring-populations.html},
	type = {Learn/Docs/Elastic Stack/Machine learning/7.8},
	urldate = {2020-07-28},
	langid = {english},
	note = {Library Catalog: www.elastic.co},
	file = {Snapshot:/home/jael/Zotero/storage/A29TVRS7/ml-configuring-populations.html:text/html}
}

@inreference{noauthor_autoregressive_2020,
	title = {Autoregressive integrated moving average},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Autoregressive_integrated_moving_average&oldid=966190870},
	abstract = {In statistics and econometrics, and in particular in time series analysis, an autoregressive integrated moving average ({ARIMA}) model is a generalization of an autoregressive moving average ({ARMA}) model.  Both of these models are fitted to time series data either to better understand the data or to predict future points in the series (forecasting). {ARIMA} models are applied in some cases where data show evidence of non-stationarity, where an initial differencing step (corresponding to the "integrated" part of the model) can be applied one or more times to eliminate the non-stationarity.The {AR} part of {ARIMA} indicates that the evolving variable of interest is regressed on its own lagged (i.e., prior) values. The {MA} part indicates that the regression error is actually a linear combination of error terms whose values occurred contemporaneously and at various times in the past. The I (for "integrated") indicates that the data values have been replaced with the difference between their values and the previous values (and this differencing process may have been performed more than once). The purpose of each of these features is to make the model fit the data as well as possible.
Non-seasonal {ARIMA} models are generally denoted {ARIMA}(p,d,q) where parameters p, d, and q are non-negative integers, p is the order (number of time lags) of the autoregressive model, d is the degree of differencing (the number of times the data have had past values subtracted), and q is the order of the moving-average model. Seasonal {ARIMA} models are usually denoted {ARIMA}(p,d,q)(P,D,Q)m, where m refers to the number of periods in each season, and the uppercase P,D,Q refer to the autoregressive, differencing, and moving average terms for the seasonal part of the {ARIMA} model.When two out of the three terms are zeros, the model may be referred to based on the non-zero parameter, dropping "{AR}", "I" or "{MA}" from the acronym describing the model. For example, 
  
    
      
        
          {ARIMA}
        
        (
        1
        ,
        0
        ,
        0
        )
      
    
    \{{\textbackslash}displaystyle \{{\textbackslash}text\{{ARIMA}\}\}(1,0,0)\}
   is {AR}(1), 
  
    
      
        
          {ARIMA}
        
        (
        0
        ,
        1
        ,
        0
        )
      
    
    \{{\textbackslash}displaystyle \{{\textbackslash}text\{{ARIMA}\}\}(0,1,0)\}
   is I(1), and 
  
    
      
        
          {ARIMA}
        
        (
        0
        ,
        0
        ,
        1
        )
      
    
    \{{\textbackslash}displaystyle \{{\textbackslash}text\{{ARIMA}\}\}(0,0,1)\}
   is {MA}(1).
{ARIMA} models can be estimated following the Box–Jenkins approach.},
	booktitle = {Wikipedia},
	urldate = {2020-07-29},
	date = {2020-07-05},
	langid = {english},
	note = {Page Version {ID}: 966190870},
	file = {Snapshot:/home/jael/Zotero/storage/N9CJEJ32/2020 - Autoregressive integrated moving average.html:text/html}
}

@inreference{noauthor_moyenne_2020,
	title = {Moyenne mobile},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://fr.wikipedia.org/w/index.php?title=Moyenne_mobile&oldid=171277243},
	abstract = {La moyenne mobile, ou moyenne glissante, est un type de moyenne statistique utilisée pour analyser des séries ordonnées de données, le plus souvent des séries temporelles, en supprimant les fluctuations transitoires de façon à en souligner les tendances à plus long terme.  Cette moyenne est dite mobile parce qu'elle est recalculée de façon continue, en utilisant à chaque calcul un sous-ensemble d'éléments dans lequel un nouvel élément remplace le plus ancien ou s'ajoute au sous-ensemble.
Ce type de moyenne est utilisé généralement comme méthode de lissage de valeurs, en particulier dans le domaine financier pour l'analyse technique de cours boursiers.
Mathématiquement, toute moyenne mobile est un exemple de convolution. Physiquement, une moyenne mobile est un filtre passe-bas et possède ainsi un lien profond avec le traitement du signal. En particulier, la moyenne mobile exponentielle, que nous allons aborder plus loin, est un filtre linéaire passe-bas du premier ordre tout à fait classique.},
	booktitle = {Wikipédia},
	urldate = {2020-07-29},
	date = {2020-05-25},
	langid = {french},
	note = {Page Version {ID}: 171277243},
	file = {Snapshot:/home/jael/Zotero/storage/FXBDRTL6/index.html:text/html}
}

@inreference{noauthor_processus_2020,
	title = {Processus autorégressif},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://fr.wikipedia.org/w/index.php?title=Processus_autor%C3%A9gressif&oldid=171811973},
	abstract = {Un processus autorégressif est un modèle de régression pour séries temporelles dans lequel la série est expliquée par ses valeurs passées plutôt que par d'autres variables.},
	booktitle = {Wikipédia},
	urldate = {2020-07-29},
	date = {2020-06-08},
	langid = {french},
	note = {Page Version {ID}: 171811973},
	file = {Snapshot:/home/jael/Zotero/storage/EYIVV2UT/index.html:text/html}
}

@inreference{noauthor_stationnarite_2020,
	title = {Stationnarité d'une série temporelle},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://fr.wikipedia.org/w/index.php?title=Stationnarit%C3%A9_d%27une_s%C3%A9rie_temporelle&oldid=171114537},
	abstract = {Une des grandes questions dans l'étude de séries temporelles (ou chronologiques) est de savoir si celles-ci suivent un processus stationnaire. On entend par là le fait que la structure du processus sous-jacent supposé évolue ou non avec le temps. Si la structure reste la même, le processus est dit alors stationnaire.},
	booktitle = {Wikipédia},
	urldate = {2020-07-29},
	date = {2020-05-21},
	langid = {french},
	note = {Page Version {ID}: 171114537},
	file = {Snapshot:/home/jael/Zotero/storage/ZFHDA3JE/index.html:text/html}
}

@online{noauthor_modearima_2020,
	title = {Modèle {ARIMA} avec Python – Prévisions de séries temporelles},
	url = {https://moncoachdata.com/blog/modele-arima-avec-python/},
	abstract = {Le modèle {ARIMA} avec Python donne la possibilité de faire des prévisions basées sur des observations historiques, ce qui crée un avantage concurrentiel. Par exemple, si une organisation a la capacité de mieux prévoir les quantités vendues d'un produit, elle sera dans une position plus favorable pour optimiser les niveaux de stock. Cela peut se traduire par une augmentation des liquidités des réserves de trésorerie de l'organisation, une diminution du fonds de roulement et une amélioration de la satisfaction des clients en réduisant l'arriéré des commandes. Dans le domaine du Machine Learning, il existe un ensemble spécifique de méthodes et},
	titleaddon = {{MonCoachData}},
	urldate = {2020-07-29},
	date = {2020-01-23},
	langid = {french},
	note = {Library Catalog: moncoachdata.com
Section: Analyse de données},
	file = {Snapshot:/home/jael/Zotero/storage/RYZFKW7R/modele-arima-avec-python.html:text/html}
}

@inreference{noauthor_regression_2018,
	title = {Régression locale},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://fr.wikipedia.org/w/index.php?title=R%C3%A9gression_locale&oldid=147969596},
	abstract = {La régression locale, ou {LOESS}, est une méthode de régression non paramétrique fortement connexe qui combine plusieurs modèles de régression multiple au sein d'un méta-modèle qui repose sur la méthode des k plus proches voisins. « {LOESS} » est un acronyme qui peut être compris comme signifiant, en anglais, « {LOcally} weighted Scatterplot Smoother ».
La régression locale est une alternative possible aux méthodes habituelles de régression, comme la régression par les moindres carrés linéaire ou non linéaire, dans les cas où ces dernières s'avèrent mal adaptées. Elle combine la simplicité de régression linéaire par les moindres carrés avec la flexibilité de la régression non linéaire, en effectuant une régression simple sur des sous-ensembles locaux de données. L'un des principaux avantages de cette méthode est qu'elle rend inutile la définition d'une unique fonction globale qui décrirait le modèle de régression, puisque la méthode consiste à calculer autant de fonctions locales qu'il y a de segments de données.
Le principe de la régression locale a été initialement décrit par Cleveland (1979), puis développé et enrichi par Cleveland (1981)  et Cleveland et Devlin (1988).},
	booktitle = {Wikipédia},
	urldate = {2020-07-29},
	date = {2018-04-29},
	langid = {french},
	note = {Page Version {ID}: 147969596},
	file = {Snapshot:/home/jael/Zotero/storage/H43DM4VM/2018 - Régression locale.html:text/html}
}

@inreference{noauthor_seasonality_2020,
	title = {Seasonality},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Seasonality&oldid=966842186},
	abstract = {In time series data, seasonality is the presence of variations that occur at specific regular intervals less than a year, such as weekly, monthly, or quarterly. Seasonality may be caused by various factors, such as weather, vacation, and holidays and consists of periodic, repetitive, and generally regular and predictable patterns in the levels of a time series.
Seasonal fluctuations in a time series can be contrasted with cyclical patterns. The latter occur when the data exhibits rises and falls that are not of a fixed period. Such non-seasonal fluctuations are usually due to economic conditions and are often related to the "business cycle"; their period usually extends beyond a single year, and the fluctuations are usually of at least two years.Organisations facing seasonal variations, such as ice-cream vendors, are often interested in knowing their performance relative to the normal seasonal variation. Seasonal variations in the labour market can be attributed to the entrance of school leavers into the job market as they aim to contribute to the workforce upon the completion of their schooling. These regular changes are of less interest to those who study employment data than the variations that occur due to the underlying state of the economy; their focus is on how unemployment in the workforce has changed, despite the impact of the regular seasonal variations.It is necessary for organisations to identify and measure seasonal variations within their market to help them plan for the future. This can prepare them for the temporary increases or decreases in labour requirements and inventory as demand for their product or service fluctuates over certain periods. This may require training, periodic maintenance, and so forth that can be organized in advance. Apart from these considerations, the organisations need to know if variation they have experienced has been more or less than the expected amount, beyond what the usual seasonal variations account for.},
	booktitle = {Wikipedia},
	urldate = {2020-07-29},
	date = {2020-07-09},
	langid = {english},
	note = {Page Version {ID}: 966842186},
	file = {Snapshot:/home/jael/Zotero/storage/EAIF74V4/index.html:text/html}
}

@online{wheeler_anomaly_2018,
	title = {Anomaly Detection Using {STL}},
	url = {https://medium.com/wwblog/anomaly-detection-using-stl-76099c9fd5a7},
	abstract = {This post describes a way to model the midpoint of a time series involving seasonal and trend components. We’ll take a high-level look at…},
	titleaddon = {Medium},
	author = {Wheeler, Willie},
	urldate = {2020-07-29},
	date = {2018-07-14},
	langid = {english},
	note = {Library Catalog: medium.com},
	file = {Snapshot:/home/jael/Zotero/storage/4XCMG8XG/anomaly-detection-using-stl-76099c9fd5a7.html:text/html}
}

@software{noauthor_twitteranomalydetection_2020,
	title = {twitter/{AnomalyDetection}},
	rights = {{GPL}-3.0 License         ,                 {GPL}-3.0 License},
	url = {https://github.com/twitter/AnomalyDetection},
	abstract = {Anomaly Detection with R. Contribute to twitter/{AnomalyDetection} development by creating an account on {GitHub}.},
	publisher = {Twitter, Inc.},
	urldate = {2020-07-29},
	date = {2020-07-28},
	note = {original-date: 2014-12-09T17:46:24Z}
}

@online{noauthor_135173_nodate,
	title = {1.3.5.17.3. Generalized Extreme Studentized Deviate Test for Outliers},
	url = {https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h3.htm},
	urldate = {2020-07-29},
	file = {1.3.5.17.3. Generalized Extreme Studentized Deviate Test for Outliers:/home/jael/Zotero/storage/HW3X5W3L/eda35h3.html:text/html}
}

@online{noauthor_introducing_nodate,
	title = {Introducing practical and robust anomaly detection in a time series},
	url = {https://blog.twitter.com/engineering/en_us/a/2015/introducing-practical-and-robust-anomaly-detection-in-a-time-series.html},
	abstract = {Introducing practical and robust anomaly detection in a time series},
	urldate = {2020-07-29},
	langid = {english},
	note = {Library Catalog: blog.twitter.com},
	file = {Snapshot:/home/jael/Zotero/storage/IR9ZH2LK/introducing-practical-and-robust-anomaly-detection-in-a-time-series.html:text/html}
}

@online{noauthor_prophet_nodate,
	title = {Prophet},
	url = {http://facebook.github.io/prophet/},
	abstract = {Prophet is a forecasting procedure implemented in R and Python. It is fast and provides completely automated forecasts that can be tuned by hand by data scientists and analysts.},
	titleaddon = {Prophet},
	urldate = {2020-07-29},
	note = {Library Catalog: facebook.github.io},
	file = {Snapshot:/home/jael/Zotero/storage/HN2LQHN4/prophet.html:text/html}
}

@online{noauthor_quick_nodate,
	title = {Quick Start},
	url = {http://facebook.github.io/prophet/docs/quick_start.html},
	abstract = {Prophet is a forecasting procedure implemented in R and Python. It is fast and provides completely automated forecasts that can be tuned by hand by data scientists and analysts.},
	titleaddon = {Prophet},
	urldate = {2020-07-29},
	note = {Library Catalog: facebook.github.io},
	file = {Snapshot:/home/jael/Zotero/storage/7LGXYXK5/quick_start.html:text/html}
}

@online{lobo_detecting_2020,
	title = {Detecting real-time and unsupervised anomalies in streaming data: a starting point},
	url = {https://towardsdatascience.com/detecting-real-time-and-unsupervised-anomalies-in-streaming-data-a-starting-point-760a4bacbdf8},
	shorttitle = {Detecting real-time and unsupervised anomalies in streaming data},
	abstract = {Sensors enable the Internet of Things ({IoT}) by collecting the data for smarter decisions in all kinds of systems. Data are usually…},
	titleaddon = {Medium},
	author = {Lobo, Jesus L.},
	urldate = {2020-07-29},
	date = {2020-02-12},
	langid = {english},
	note = {Library Catalog: towardsdatascience.com},
	file = {Snapshot:/home/jael/Zotero/storage/3VMQCB2Z/detecting-real-time-and-unsupervised-anomalies-in-streaming-data-a-starting-point-760a4bacbdf8.html:text/html}
}

@inreference{noauthor_reseau_2020,
	title = {Réseau de neurones récurrents},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://fr.wikipedia.org/w/index.php?title=R%C3%A9seau_de_neurones_r%C3%A9currents&oldid=168319282},
	abstract = {Un réseau de neurones récurrents est un réseau de neurones artificiels présentant des connexions récurrentes. Un réseau de neurones récurrents est constitué d'unités (neurones) interconnectées interagissant non-linéairement et pour lequel il existe au moins un cycle dans la structure. Les unités sont reliées par des arcs (synapses) qui possèdent un poids. La sortie d'un neurone est une combinaison non linéaire de ses entrées. 
Les réseaux de neurones récurrents sont adaptés pour des données d'entrée de taille variable. Ils conviennent en particulier pour l'analyse de séries temporelles. Ils sont utilisés en reconnaissance automatique de la parole ou de l'écriture manuscrite - plus en général en reconnaissance de formes - ou encore en traduction automatique. « Dépliés », ils sont comparables à des réseaux de neurones classiques avec des contraintes d'égalité entre les poids du réseau (voir schéma à droite). Les techniques d'entraînement du réseau sont les mêmes que pour les réseaux classiques (rétropropagation du gradient), néanmoins les réseaux de neurones récurrents se heurtent au problème de disparition du gradient pour apprendre à mémoriser des évènements passés. Des architectures particulières répondent à ce dernier problème, on peut citer en particulier les réseaux Long short-term memory. On peut étudier les comportements des réseaux de neurones récurrents avec la théorie des bifurcations, mais la complexité de cette étude augmente très rapidement avec le nombre de neurones.},
	booktitle = {Wikipédia},
	urldate = {2020-07-29},
	date = {2020-03-11},
	langid = {french},
	note = {Page Version {ID}: 168319282},
	file = {Snapshot:/home/jael/Zotero/storage/M8XXE3B2/index.html:text/html}
}

@online{noauthor_market_2017,
	title = {Market Basket Analysis: Understanding Customer Behaviour},
	url = {https://select-statistics.co.uk/blog/market-basket-analysis-understanding-customer-behaviour/},
	shorttitle = {Market Basket Analysis},
	abstract = {In a previous blog post, we discussed how supermarkets use data to better understand consumer needs and, ultimately, increase their overall spend. One of},
	titleaddon = {Select Statistical Consultants},
	urldate = {2020-07-30},
	date = {2017-01-24},
	langid = {english},
	file = {Snapshot:/home/jael/Zotero/storage/QEEKWGMB/2017 - Market Basket Analysis Understanding Customer Beh.html:text/html}
}

@online{li_gentle_2017,
	title = {A Gentle Introduction on Market Basket Analysis — Association Rules},
	url = {https://towardsdatascience.com/a-gentle-introduction-on-market-basket-analysis-association-rules-fa4b986a40ce},
	abstract = {Introduction},
	titleaddon = {Medium},
	author = {Li, Susan},
	urldate = {2020-07-30},
	date = {2017-09-27},
	langid = {english},
	note = {Library Catalog: towardsdatascience.com},
	file = {Snapshot:/home/jael/Zotero/storage/ZXS3IMGX/a-gentle-introduction-on-market-basket-analysis-association-rules-fa4b986a40ce.html:text/html}
}

@online{noauthor_introduction_nodate,
	title = {Introduction — statsmodels},
	url = {https://www.statsmodels.org/stable/index.html},
	urldate = {2020-07-30},
	file = {Introduction — statsmodels:/home/jael/Zotero/storage/9QHIJMNL/index.html:text/html}
}

@online{ashrapov_anomaly_2020,
	title = {Anomaly detection in time series with Prophet library},
	url = {https://towardsdatascience.com/anomaly-detection-time-series-4c661f6f165f},
	abstract = {Find outliers in time series and plot in few lines of code},
	titleaddon = {Medium},
	author = {Ashrapov, Insaf},
	urldate = {2020-07-30},
	date = {2020-06-04},
	langid = {english},
	note = {Library Catalog: towardsdatascience.com},
	file = {Snapshot:/home/jael/Zotero/storage/BBNMMCKC/anomaly-detection-time-series-4c661f6f165f.html:text/html}
}

@online{noauthor_introduction_nodate-1,
	title = {Introduction to Market Basket Analysis in Python - Practical Business Python},
	url = {https://pbpython.com/market-basket-analysis.html},
	urldate = {2020-07-30},
	file = {Introduction to Market Basket Analysis in Python - Practical Business Python:/home/jael/Zotero/storage/YZUGQ8VB/market-basket-analysis.html:text/html}
}

@article{raschka_mlxtend_2018,
	title = {{MLxtend}: Providing machine learning and data science utilities and extensions to Python’s scientific computing stack},
	volume = {3},
	issn = {2475-9066},
	url = {http://joss.theoj.org/papers/10.21105/joss.00638},
	doi = {10.21105/joss.00638},
	shorttitle = {{MLxtend}},
	pages = {638},
	number = {24},
	journaltitle = {Journal of Open Source Software},
	shortjournal = {{JOSS}},
	author = {Raschka, Sebastian},
	urldate = {2020-07-30},
	date = {2018-04-22},
	file = {Texte intégral:/home/jael/Zotero/storage/XD6PNNQI/Raschka - 2018 - MLxtend Providing machine learning and data scien.pdf:application/pdf}
}